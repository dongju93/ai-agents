```markdown
# Dongju Lee

**Mid-Level Python Software Engineer**

üìß spdlqj011@gmail.com | üì± +82-10-3247-8760  
üåê Portfolio: [Notion Portfolio](https://www.notion.so/dongjulee/Portfolio-e0c6d62ecfba4c3996a920c69322afd3) | GitHub: [github.com/dongju93](https://github.com/dongju93)  
üìç Seoul, South Korea | Open to relocation/Hybrid work in Boston, MA

---

## Professional Summary

Passionate Backend Developer with 4+ years of experience designing, developing, and maintaining Python-based backend services in agile environments. Expertise in FastAPI, Django, PostgreSQL, and Redis for building scalable, high-performance RESTful APIs. Skilled in containerization with Docker, orchestration with Kubernetes, and implementing unit/integration testing. Strong collaborator in cross-functional teams, code reviews, and CI/CD practices.

---

## Technical Skills

- **Languages & Frameworks:** Python, FastAPI, Django, RESTful APIs, GraphQL, gRPC
- **Databases & Caching:** PostgreSQL, MariaDB, MySQL, MongoDB, Redis, Elasticsearch
- **Containerization & DevOps:** Docker, Kubernetes, Jenkins, NGINX, Git
- **Testing & Quality:** Pytest, MyPy, Pyright, Ruff, Pre-commit hooks
- **Monitoring & Logging:** Prometheus, Grafana, InfluxDB, Grafana Loki
- **Data Processing:** Polars, Pandas, ETL Pipelines

---

## Professional Experience

### Backend Engineer (Assistant Manager)

**PINOLIKE Co., LTD.** | Seoul, South Korea  
_May 2024 ‚Äì Present_

- Architected and maintained asynchronous backend services using Python and FastAPI with Pydantic for robust data validation.
- Designed and implemented RESTful API endpoints with JWT-based authentication (Access/Refresh tokens) to support modular microservices.
- Built multi-database architecture: PostgreSQL/MariaDB for transactional data, Redis for caching, and Elasticsearch for full-text search.
- Developed event-driven communication via Redis Pub/Sub for real-time data processing workflows.
- Containerized applications using Docker and orchestrated deployments on Kubernetes clusters.
- Collaborated with frontend and DevOps teams on API design, integration, and deployment pipelines.
- Wrote comprehensive unit and integration tests with Pytest; integrated static analysis tools (Ruff, Pyright) into a CI pipeline.
- Participated in Agile ceremonies, peer code reviews, and maintained Git-based version control best practices.
- Implemented monitoring and logging stacks (Prometheus, Grafana, InfluxDB, Grafana Loki) for service health and performance metrics.

### Project Manager & Python Developer

**CLUMELL Co., LTD.** | Seoul, South Korea  
_June 2023 ‚Äì April 2024_

- Designed and developed a high-throughput log data processing pipeline in Python and Rust, handling 1,000+ JSON IoC reports per cycle.
- Created RESTful data ingestion endpoints and sample integration code for external partners.
- Built an Elastic Stack‚Äìbased log collection system with Sysmon for endpoint monitoring.
- Established QA and feedback workflows via Notion; coordinated sprints and technical handoffs between cross-functional teams.

### IT Consultant & Infrastructure Engineer

**Daily Soft Co., LTD.** | Seoul, South Korea  
_January 2021 ‚Äì June 2023_

- Led PostgreSQL data migration and Docker-based deployments for the National Debt Management System.
- Developed Python ETL scripts and Jupyter notebooks to analyze legal and financial datasets, enabling data-driven insights.
- Designed and configured Linux-based application servers, including SFTP environments and network security settings.
- Managed infrastructure vendor selection and cloud environment setup for government digital transformation projects.

---

## Education

**Bachelor of Science in Information and Communication Engineering**  
Induk University, Seoul, South Korea | _March 2012 ‚Äì February 2019_  
GPA: 3.54/4.5

---

## Certifications

- **Information Processing Engineer** | Korea Human Resources Development Service | _May 2019_

---

## Projects

**AI Agent Collaboration System** (CrewAI, Python, LLM)

- Building a multi-agent framework for automated news gathering, summarization, and curation.
- Implementing RAG pipelines and autonomous workflows to enhance LLM-driven analysis.

---

## Additional Information

- Actively practice TDD and agile methodologies.
- Continuous learner: track Python ecosystem updates, explore new libraries, and deepen cloud and containerization expertise.
- Open to hybrid work and relocation to Boston, MA.
```
